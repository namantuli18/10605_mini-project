{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6_xSmL5Ud-L"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8-4wiwDUd-N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "mMW4Q-RtJxiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5esWnmZ1Ud-O",
        "outputId": "0540c7b7-0859-4b83-c450-748824669987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.tar.gz\tsample_data  train_images.pkl\n",
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ],
      "source": [
        "# untar\n",
        "!ls\n",
        "!tar -xvzf dataset.tar.gz\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG6sBNS2Ud-P"
      },
      "outputs": [],
      "source": [
        "train_images = torch.tensor(train_images, dtype=torch.float32)\n",
        "val_images = torch.tensor(val_images, dtype=torch.float32)\n",
        "\n",
        "train_images = train_images.permute(0, 3, 1, 2)\n",
        "val_images = val_images.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zvu3f3yUd-P"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(train_images,\n",
        "                              torch.tensor(train_labels.squeeze(), dtype=torch.long))\n",
        "val_dataset = TensorDataset(val_images,\n",
        "                            torch.tensor(val_labels.squeeze(), dtype=torch.long))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BBS787DUd-Q"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzgqu2UbUd-Q"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # First block: Conv -> ReLU -> Conv -> ReLU -> MaxPool -> Dropout\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=0, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            # Second block: Conv -> ReLU -> Conv -> ReLU -> MaxPool -> Dropout\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=0, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            # Flatten layer\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # Fully connected block: Dense -> ReLU -> Dropout -> Dense -> Softmax\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 5),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYW_6NgEUd-Q"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "summary(model, input_size=(3, 25, 25))"
      ],
      "metadata": {
        "id": "z_toyD_1VQsK",
        "outputId": "50f30b23-9003-45aa-f487-715e791ec18d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 25, 25]             896\n",
            "              ReLU-2           [-1, 32, 25, 25]               0\n",
            "            Conv2d-3           [-1, 32, 23, 23]           9,248\n",
            "              ReLU-4           [-1, 32, 23, 23]               0\n",
            "         MaxPool2d-5           [-1, 32, 11, 11]               0\n",
            "           Dropout-6           [-1, 32, 11, 11]               0\n",
            "            Conv2d-7           [-1, 64, 11, 11]          18,496\n",
            "              ReLU-8           [-1, 64, 11, 11]               0\n",
            "            Conv2d-9             [-1, 64, 9, 9]          36,928\n",
            "             ReLU-10             [-1, 64, 9, 9]               0\n",
            "        MaxPool2d-11             [-1, 64, 4, 4]               0\n",
            "          Dropout-12             [-1, 64, 4, 4]               0\n",
            "          Flatten-13                 [-1, 1024]               0\n",
            "           Linear-14                  [-1, 512]         524,800\n",
            "             ReLU-15                  [-1, 512]               0\n",
            "          Dropout-16                  [-1, 512]               0\n",
            "           Linear-17                    [-1, 5]           2,565\n",
            "================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.86\n",
            "Params size (MB): 2.26\n",
            "Estimated Total Size (MB): 3.12\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
        "    model.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Progress bar for the training loop\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in train_loader_tqdm:\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track loss and accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Update tqdm description with current loss and accuracy\n",
        "        train_loader_tqdm.set_postfix(loss=running_loss / total, accuracy=100 * correct / total)\n",
        "\n",
        "    train_accuracy = 100 * correct / total\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    return train_loss, train_accuracy"
      ],
      "metadata": {
        "id": "wALYsoeSMN-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Progress bar for the validation loop\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations for validation\n",
        "        for inputs, labels in val_loader_tqdm:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # Update tqdm description with current validation loss and accuracy\n",
        "            val_loader_tqdm.set_postfix(loss=val_loss / total, accuracy=100 * correct / total)\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    return val_loss, val_accuracy"
      ],
      "metadata": {
        "id": "NnYV0D4VMPES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "60-Jum5EMTFT",
        "outputId": "10d7feb9-f5c2-4cee-b296-d75b876c0015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Train Loss: 1.5401, Train Acc: 28.82%, Val Loss: 1.4229, Val Acc: 38.42%\n",
            "Epoch 2/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/50], Train Loss: 1.3875, Train Acc: 39.51%, Val Loss: 1.3339, Val Acc: 41.98%\n",
            "Epoch 3/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/50], Train Loss: 1.3250, Train Acc: 43.45%, Val Loss: 1.2868, Val Acc: 43.76%\n",
            "Epoch 4/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2980576618.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2113354392.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2719010630.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \"\"\"\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'my_model_weights_1.pt', _use_new_zipfile_serialization=False)"
      ],
      "metadata": {
        "id": "-rCvWKq2S5mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os4z3KodUd-S"
      },
      "source": [
        "### Loading in saved model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('my_model_weights_1.pt', weights_only=True)\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "SRpCPbwWdrB1",
        "outputId": "6e2d18ac-dd04-4e71-bc31-b40194c075d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.model[0].weight.data.size())"
      ],
      "metadata": {
        "id": "bzvsdoBEeSTL",
        "outputId": "e2780bae-7d34-4032-d16f-f5685099076d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L1 Pruner"
      ],
      "metadata": {
        "id": "0jMgZ4s8c2sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def l1_prune(model, prune_percent):\n",
        "\n",
        "  # Hook is made to make sure we don't retrain these weights after zeroing out\n",
        "  def make_hook(mask):\n",
        "    def hook(grad):\n",
        "      return mask * grad\n",
        "    return hook\n",
        "\n",
        "\n",
        "  pruned_outputs = None\n",
        "  for module in model.model:\n",
        "    if isinstance(module, nn.Conv2d):\n",
        "      weight_mask = torch.ones_like(module.weight.data).to(device)\n",
        "      m = int(prune_percent * module.out_channels)\n",
        "\n",
        "      # Zero out pruned inputs\n",
        "      if pruned_outputs is not None:\n",
        "        module.weight.data[:, pruned_outputs, :, :] = 0.0\n",
        "        weight_mask[pruned_outputs, :, :, :] = 0.0\n",
        "\n",
        "      filters = module.weight.data.view(module.weight.data.size(0), -1)\n",
        "      l1_vals = torch.sum(torch.abs(filters), dim=1)\n",
        "\n",
        "\n",
        "      pruned_outputs = torch.topk(l1_vals, m, largest=False).indices.tolist()\n",
        "      module.weight.data[pruned_outputs, :, :, :] = 0.0\n",
        "      weight_mask[pruned_outputs, :, :, :] = 0.0\n",
        "      module.weight.register_hook(make_hook(weight_mask))\n",
        "\n",
        "      if module.bias is not None:\n",
        "        bias_mask = torch.ones_like(module.bias.data).to(device)\n",
        "        module.bias.data[pruned_outputs] = 0.0\n",
        "        bias_mask[pruned_outputs] = 0.0\n",
        "        module.bias.register_hook(make_hook(bias_mask))\n",
        "\n",
        "      out_chan = module.out_channels\n",
        "\n",
        "    if isinstance(module, nn.Linear):\n",
        "      if pruned_outputs is not None:\n",
        "        assert module.in_features % out_chan == 0\n",
        "        chan_size = module.in_features // out_chan\n",
        "\n",
        "        weight_mask = torch.ones_like(module.weight.data).to(device)\n",
        "\n",
        "\n",
        "        flattened_prune_indices = []\n",
        "        for chan_idx in pruned_outputs:\n",
        "          flattened_prune_indices.extend(range(chan_idx*chan_size, (chan_idx+1)*chan_size))\n",
        "\n",
        "        module.weight.data[:, flattened_prune_indices] = 0.0\n",
        "        weight_mask[:, flattened_prune_indices] = 0.0\n",
        "        module.weight.register_hook(make_hook(weight_mask))\n",
        "\n",
        "        pruned_outputs = None\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "-BxFi0yMc6FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = l1_prune(model, 0.3)"
      ],
      "metadata": {
        "id": "3n9N_x4TpJUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to('cuda')"
      ],
      "metadata": {
        "id": "gTqaU6tmm4FK",
        "outputId": "50806545-8bfd-4bc1-f4f2-ca03d619e35a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Dropout(p=0.25, inplace=False)\n",
              "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Dropout(p=0.25, inplace=False)\n",
              "    (12): Flatten(start_dim=1, end_dim=-1)\n",
              "    (13): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (14): ReLU()\n",
              "    (15): Dropout(p=0.5, inplace=False)\n",
              "    (16): Linear(in_features=512, out_features=5, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "print(val_loss, val_accuracy)"
      ],
      "metadata": {
        "id": "CdZm_sUJmPZ7",
        "outputId": "c8f88cc4-7775-4f9c-9241-ab795b8de389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1742661542530302 53.386138613861384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retraining loop\n",
        "num_epochs = 40\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    train_loss, train_accuracy = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, '\n",
        "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "alAx1YDPpa2o",
        "outputId": "405f0e6b-a8a6-488c-91a9-e42be1e3a2bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Train Loss: 0.9260, Train Acc: 64.27%, Val Loss: 0.9374, Val Acc: 62.53%\n",
            "Epoch 2/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/40], Train Loss: 0.9306, Train Acc: 63.48%, Val Loss: 0.9311, Val Acc: 62.65%\n",
            "Epoch 3/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/40], Train Loss: 0.9322, Train Acc: 63.84%, Val Loss: 0.9217, Val Acc: 63.09%\n",
            "Epoch 4/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/40], Train Loss: 0.9218, Train Acc: 64.13%, Val Loss: 0.9221, Val Acc: 63.13%\n",
            "Epoch 5/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/40], Train Loss: 0.9042, Train Acc: 64.64%, Val Loss: 0.9019, Val Acc: 63.49%\n",
            "Epoch 6/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/40], Train Loss: 0.8925, Train Acc: 65.38%, Val Loss: 0.8949, Val Acc: 64.44%\n",
            "Epoch 7/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/40], Train Loss: 0.8833, Train Acc: 65.78%, Val Loss: 0.8799, Val Acc: 65.58%\n",
            "Epoch 8/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/40], Train Loss: 0.8692, Train Acc: 66.50%, Val Loss: 0.8717, Val Acc: 64.75%\n",
            "Epoch 9/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/40], Train Loss: 0.8608, Train Acc: 66.99%, Val Loss: 0.8574, Val Acc: 66.06%\n",
            "Epoch 10/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/40], Train Loss: 0.8581, Train Acc: 66.78%, Val Loss: 0.8641, Val Acc: 65.82%\n",
            "Epoch 11/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/40], Train Loss: 0.8487, Train Acc: 66.96%, Val Loss: 0.8588, Val Acc: 65.27%\n",
            "Epoch 12/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/40], Train Loss: 0.8409, Train Acc: 67.51%, Val Loss: 0.8585, Val Acc: 65.62%\n",
            "Epoch 13/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/40], Train Loss: 0.8320, Train Acc: 67.66%, Val Loss: 0.8506, Val Acc: 66.26%\n",
            "Epoch 14/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/40], Train Loss: 0.8289, Train Acc: 68.21%, Val Loss: 0.8521, Val Acc: 66.18%\n",
            "Epoch 15/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/40], Train Loss: 0.8148, Train Acc: 68.20%, Val Loss: 0.8599, Val Acc: 65.78%\n",
            "Epoch 16/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/40], Train Loss: 0.8037, Train Acc: 69.21%, Val Loss: 0.8321, Val Acc: 66.53%\n",
            "Epoch 17/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/40], Train Loss: 0.8082, Train Acc: 68.93%, Val Loss: 0.8350, Val Acc: 67.09%\n",
            "Epoch 18/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/40], Train Loss: 0.7968, Train Acc: 69.25%, Val Loss: 0.8341, Val Acc: 66.85%\n",
            "Epoch 19/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/40], Train Loss: 0.7997, Train Acc: 69.33%, Val Loss: 0.8334, Val Acc: 67.64%\n",
            "Epoch 20/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/40], Train Loss: 0.7885, Train Acc: 69.59%, Val Loss: 0.8250, Val Acc: 67.80%\n",
            "Epoch 21/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/40], Train Loss: 0.7860, Train Acc: 69.75%, Val Loss: 0.8369, Val Acc: 66.93%\n",
            "Epoch 22/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/40], Train Loss: 0.7818, Train Acc: 70.25%, Val Loss: 0.8224, Val Acc: 66.73%\n",
            "Epoch 23/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/40], Train Loss: 0.7734, Train Acc: 70.22%, Val Loss: 0.8193, Val Acc: 67.80%\n",
            "Epoch 24/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/40], Train Loss: 0.7737, Train Acc: 70.49%, Val Loss: 0.8217, Val Acc: 67.56%\n",
            "Epoch 25/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/40], Train Loss: 0.7690, Train Acc: 70.74%, Val Loss: 0.8126, Val Acc: 68.12%\n",
            "Epoch 26/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/40], Train Loss: 0.7643, Train Acc: 70.88%, Val Loss: 0.8279, Val Acc: 67.37%\n",
            "Epoch 27/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/40], Train Loss: 0.7570, Train Acc: 70.89%, Val Loss: 0.8273, Val Acc: 67.60%\n",
            "Epoch 28/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/40], Train Loss: 0.7518, Train Acc: 70.92%, Val Loss: 0.8114, Val Acc: 68.44%\n",
            "Epoch 29/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/40], Train Loss: 0.7448, Train Acc: 71.60%, Val Loss: 0.8074, Val Acc: 68.44%\n",
            "Epoch 30/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/40], Train Loss: 0.7457, Train Acc: 71.33%, Val Loss: 0.8148, Val Acc: 67.64%\n",
            "Epoch 31/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/40], Train Loss: 0.7390, Train Acc: 71.93%, Val Loss: 0.8191, Val Acc: 67.49%\n",
            "Epoch 32/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/40], Train Loss: 0.7355, Train Acc: 72.01%, Val Loss: 0.8001, Val Acc: 68.63%\n",
            "Epoch 33/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [33/40], Train Loss: 0.7336, Train Acc: 72.07%, Val Loss: 0.8036, Val Acc: 68.63%\n",
            "Epoch 34/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [34/40], Train Loss: 0.7293, Train Acc: 72.33%, Val Loss: 0.8042, Val Acc: 68.32%\n",
            "Epoch 35/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/40], Train Loss: 0.7222, Train Acc: 72.17%, Val Loss: 0.8084, Val Acc: 68.20%\n",
            "Epoch 36/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/40], Train Loss: 0.7256, Train Acc: 72.28%, Val Loss: 0.8002, Val Acc: 68.75%\n",
            "Epoch 37/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/40], Train Loss: 0.7187, Train Acc: 72.35%, Val Loss: 0.7984, Val Acc: 68.75%\n",
            "Epoch 38/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/40], Train Loss: 0.7165, Train Acc: 72.67%, Val Loss: 0.8063, Val Acc: 68.44%\n",
            "Epoch 39/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/40], Train Loss: 0.7054, Train Acc: 73.10%, Val Loss: 0.8021, Val Acc: 68.71%\n",
            "Epoch 40/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/40], Train Loss: 0.7114, Train Acc: 72.87%, Val Loss: 0.8014, Val Acc: 68.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_sparsity(model):\n",
        "  total = 0\n",
        "  zero = 0\n",
        "  for param in model.parameters():\n",
        "    total += param.numel()\n",
        "    zero += (param.data == 0.0).sum().item()\n",
        "\n",
        "  return zero/total"
      ],
      "metadata": {
        "id": "YKh_OdQhpeTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_sparsity(model)"
      ],
      "metadata": {
        "id": "hiKQWtoFp2Tn",
        "outputId": "a5150cf6-9d50-44a7-cf93-511eeb4e8986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31733433625721624"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'my_model_weights_lr_prune_30.pt', _use_new_zipfile_serialization=False)"
      ],
      "metadata": {
        "id": "ejfaU9jkq4xa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}